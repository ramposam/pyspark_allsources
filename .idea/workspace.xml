<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="ChangeListManager">
    <list default="true" id="a6815277-4383-49c3-898f-72751992d6b0" name="Default Changelist" comment="">
      <change afterPath="$PROJECT_DIR$/airflow_practise/test1.py" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/airflow_practise/test2.py" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/com/rposam/process/tojson/CsvToJson.py" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/com/rposam/process/tojson/__init__.py" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/output/emp_mgr/.part-00000-b1c64971-c3f5-4fc8-8e43-333ef923b595-c000.snappy.parquet.crc" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/output/emp_mgr/part-00000-b1c64971-c3f5-4fc8-8e43-333ef923b595-c000.snappy.parquet" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/output/mgr_details.json/._SUCCESS.crc" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/output/mgr_details.json/.part-00000-14548209-76ba-4e97-ac04-2c4cdbe278c5-c000.json.crc" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/output/mgr_details.json/_SUCCESS" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/output/mgr_details.json/part-00000-14548209-76ba-4e97-ac04-2c4cdbe278c5-c000.json" afterDir="false" />
      <change afterPath="$PROJECT_DIR$/pyspark_allsources.zip" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/app-logs/hdfstoawss3.log" beforeDir="false" afterPath="$PROJECT_DIR$/app-logs/hdfstoawss3.log" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/csv/emp/emp.csv" beforeDir="false" afterPath="$PROJECT_DIR$/csv/emp/emp.csv" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/output/emp_mgr/.part-00000-4924a04e-a855-4967-b596-fc28ddda8890-c000.snappy.parquet.crc" beforeDir="false" />
      <change beforePath="$PROJECT_DIR$/output/emp_mgr/part-00000-4924a04e-a855-4967-b596-fc28ddda8890-c000.snappy.parquet" beforeDir="false" />
    </list>
    <option name="EXCLUDED_CONVERTED_TO_IGNORED" value="true" />
    <option name="SHOW_DIALOG" value="false" />
    <option name="HIGHLIGHT_CONFLICTS" value="true" />
    <option name="HIGHLIGHT_NON_ACTIVE_CHANGELIST" value="false" />
    <option name="LAST_RESOLUTION" value="IGNORE" />
  </component>
  <component name="FileTemplateManagerImpl">
    <option name="RECENT_TEMPLATES">
      <list>
        <option value="Python Script" />
      </list>
    </option>
  </component>
  <component name="Git.Settings">
    <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />
    <option name="ROOT_SYNC" value="DONT_SYNC" />
  </component>
  <component name="ProjectId" id="1kjXlHnG5pCzY8zoisx1hnxAqgv" />
  <component name="ProjectLevelVcsManager">
    <ConfirmationsSetting value="2" id="Add" />
  </component>
  <component name="PropertiesComponent">
    <property name="ASKED_ADD_EXTERNAL_FILES" value="true" />
    <property name="SHARE_PROJECT_CONFIGURATION_FILES" value="true" />
    <property name="last_opened_file_path" value="$PROJECT_DIR$" />
    <property name="settings.editor.selected.configurable" value="com.jetbrains.python.configuration.PythonContentEntriesConfigurable" />
  </component>
  <component name="RecentsManager">
    <key name="MoveFile.RECENT_KEYS">
      <recent name="C:\Users\91889\PycharmProjects\GitProjects\pyspark_allsources\schema" />
      <recent name="C:\Users\91889\PycharmProjects\GitProjects\pyspark_allsources\output\avroschema" />
      <recent name="C:\Users\91889\PycharmProjects\Spark-Streaming\pyspark_allsources\csv\emp\emp2.csv" />
      <recent name="C:\Users\91889\PycharmProjects\Spark-Streaming\pyspark_allsources\csv\emp2" />
    </key>
    <key name="CopyFile.RECENT_KEYS">
      <recent name="C:\Users\91889\PycharmProjects\Spark-Streaming\pyspark_allsources\json\baddatafiles" />
      <recent name="C:\Users\91889\PycharmProjects\Spark-Streaming\pyspark_allsources\csv\badrecords" />
      <recent name="C:\Users\91889\PycharmProjects\Spark-Streaming\pyspark_allsources\csv\emp" />
      <recent name="C:\Users\91889\PycharmProjects\Spark-Streaming\pyspark_allsources\csv" />
      <recent name="C:\Users\91889\PycharmProjects\Spark-Streaming\pyspark_allsources\log" />
    </key>
  </component>
  <component name="RunDashboard">
    <option name="ruleStates">
      <list>
        <RuleState>
          <option name="name" value="ConfigurationTypeDashboardGroupingRule" />
        </RuleState>
        <RuleState>
          <option name="name" value="StatusDashboardGroupingRule" />
        </RuleState>
      </list>
    </option>
  </component>
  <component name="RunManager" selected="Python.CsvToJson">
    <configuration name="CsvToJson" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="test" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/com/rposam/process/tojson/CsvToJson.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="PostgrecopyVSDataFrameWriter" type="PythonConfigurationType" factoryName="Python">
      <module name="test" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/com/rposam/jdbc/PostgrecopyVSDataFrameWriter.py" />
      <option name="PARAMETERS" value="psycopyg.properties csv\emp" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="ReadAvroWriteToJdbcPostgres" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="test" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/com/rposam/process/etlpipeline/airflow/ReadAvroWriteToJdbcPostgres.py" />
      <option name="PARAMETERS" value="output/emp_mgr_avro spark.emp_mgr" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="ReadCSVWriteToParquet" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="test" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/com/rposam/process/etlpipeline/airflow/ReadCSVWriteToParquet.py" />
      <option name="PARAMETERS" value="csv\emp output\emp_mgr" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="ReadParquetWriteToAvro" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="test" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/com/rposam/process/etlpipeline/airflow/ReadParquetWriteToAvro.py" />
      <option name="PARAMETERS" value="output\emp_mgr output\emp_mgr_avro" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="WriteToJDBCPostgres" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="test" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/com/rposam/process/json/WriteToJDBCPostgres.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration default="true" type="PythonConfigurationType" factoryName="Python">
      <module name="pyspark_allsources" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="" />
      <option name="IS_MODULE_SDK" value="false" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <option name="SCRIPT_NAME" value="" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration default="true" type="Tox" factoryName="Tox">
      <module name="pyspark_allsources" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="" />
      <option name="IS_MODULE_SDK" value="false" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <method v="2" />
    </configuration>
    <configuration default="true" type="tests" factoryName="Doctests">
      <module name="pyspark_allsources" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="" />
      <option name="IS_MODULE_SDK" value="false" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <option name="SCRIPT_NAME" value="" />
      <option name="CLASS_NAME" value="" />
      <option name="METHOD_NAME" value="" />
      <option name="FOLDER_NAME" value="" />
      <option name="TEST_TYPE" value="TEST_SCRIPT" />
      <option name="PATTERN" value="" />
      <option name="USE_PATTERN" value="false" />
      <method v="2" />
    </configuration>
    <configuration default="true" type="tests" factoryName="py.test">
      <module name="pyspark_allsources" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="" />
      <option name="IS_MODULE_SDK" value="false" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <option name="_new_keywords" value="&quot;&quot;" />
      <option name="_new_additionalArguments" value="&quot;&quot;" />
      <option name="_new_target" value="&quot;&quot;" />
      <option name="_new_targetType" value="&quot;PATH&quot;" />
      <method v="2" />
    </configuration>
    <list>
      <item itemvalue="Python.PostgrecopyVSDataFrameWriter" />
      <item itemvalue="Python.ReadCSVWriteToParquet" />
      <item itemvalue="Python.ReadParquetWriteToAvro" />
      <item itemvalue="Python.ReadAvroWriteToJdbcPostgres" />
      <item itemvalue="Python.CsvToJson" />
      <item itemvalue="Python.WriteToJDBCPostgres" />
    </list>
    <recent_temporary>
      <list>
        <item itemvalue="Python.CsvToJson" />
        <item itemvalue="Python.WriteToJDBCPostgres" />
        <item itemvalue="Python.ReadCSVWriteToParquet" />
        <item itemvalue="Python.ReadAvroWriteToJdbcPostgres" />
        <item itemvalue="Python.ReadParquetWriteToAvro" />
      </list>
    </recent_temporary>
  </component>
  <component name="SvnConfiguration">
    <configuration />
  </component>
  <component name="TaskManager">
    <task active="true" id="Default" summary="Default task">
      <changelist id="a6815277-4383-49c3-898f-72751992d6b0" name="Default Changelist" comment="" />
      <created>1606215124067</created>
      <option name="number" value="Default" />
      <option name="presentableId" value="Default" />
      <updated>1606215124067</updated>
    </task>
    <task id="LOCAL-00001" summary="Removed some comments from file">
      <created>1610876422961</created>
      <option name="number" value="00001" />
      <option name="presentableId" value="LOCAL-00001" />
      <option name="project" value="LOCAL" />
      <updated>1610876422961</updated>
    </task>
    <task id="LOCAL-00002" summary="Added etl pipeline module to verify on airflow scheduler">
      <created>1610981442653</created>
      <option name="number" value="00002" />
      <option name="presentableId" value="LOCAL-00002" />
      <option name="project" value="LOCAL" />
      <updated>1610981442653</updated>
    </task>
    <task id="LOCAL-00003" summary="Added etl pipeline module to verify on airflow scheduler">
      <created>1612247965133</created>
      <option name="number" value="00003" />
      <option name="presentableId" value="LOCAL-00003" />
      <option name="project" value="LOCAL" />
      <updated>1612247965134</updated>
    </task>
    <option name="localTasksCounter" value="4" />
    <servers />
  </component>
  <component name="Vcs.Log.Tabs.Properties">
    <option name="TAB_STATES">
      <map>
        <entry key="MAIN">
          <value>
            <State>
              <option name="COLUMN_ORDER" />
            </State>
          </value>
        </entry>
      </map>
    </option>
  </component>
  <component name="VcsManagerConfiguration">
    <option name="ADD_EXTERNAL_FILES_SILENTLY" value="true" />
    <MESSAGE value="Removed some comments from file" />
    <MESSAGE value="Added etl pipeline module to verify on airflow scheduler" />
    <option name="LAST_COMMIT_MESSAGE" value="Added etl pipeline module to verify on airflow scheduler" />
  </component>
  <component name="XDebuggerManager">
    <breakpoint-manager>
      <breakpoints>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/com/rposam/jdbc/psycopg2vsSparkDataFrame.py</url>
          <line>62</line>
          <option name="timeStamp" value="2" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/com/rposam/jdbc/psycopg2vsSparkDataFrame.py</url>
          <line>63</line>
          <option name="timeStamp" value="3" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/com/rposam/jdbc/psycopg2vsSparkDataFrame.py</url>
          <line>64</line>
          <option name="timeStamp" value="4" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/com/rposam/process/udf/CustomUDFEmailGender.py</url>
          <line>29</line>
          <option name="timeStamp" value="5" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/com/rposam/process/udf/CustomUDFEmailGender.py</url>
          <line>30</line>
          <option name="timeStamp" value="6" />
        </line-breakpoint>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/com/rposam/process/udf/CustomUDFEmailGender.py</url>
          <line>31</line>
          <option name="timeStamp" value="7" />
        </line-breakpoint>
      </breakpoints>
    </breakpoint-manager>
  </component>
</project>